{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sen_dataset.csv'\n",
    "dataset = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset\n",
    "dataset = dataset[dataset['Sentiment Label'] != 'Sentiment Label']\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['Encoded Label'] = label_encoder.fit_transform(dataset['Sentiment Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = dataset['Tamil Transcript']\n",
    "y = dataset['Encoded Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class for PyTorch\n",
    "class TamilDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets and dataloaders\n",
    "max_length = 128\n",
    "train_dataset = TamilDataset(X_train, y_train, tokenizer, max_length)\n",
    "test_dataset = TamilDataset(X_test, y_test, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a compute_metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), axis=1).numpy()\n",
    "    labels = torch.tensor(labels).numpy()\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1\": f1_score(labels, predictions, average=\"weighted\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_19808\\117654359.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472eaccb8ae94dda8baefe19a7ddd91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0662, 'grad_norm': 3.549680233001709, 'learning_rate': 1.9642857142857145e-05, 'epoch': 0.18}\n",
      "{'loss': 2.1014, 'grad_norm': 3.544799327850342, 'learning_rate': 1.928571428571429e-05, 'epoch': 0.36}\n",
      "{'loss': 2.0974, 'grad_norm': 3.2842206954956055, 'learning_rate': 1.892857142857143e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9807, 'grad_norm': 8.861156463623047, 'learning_rate': 1.8571428571428575e-05, 'epoch': 0.71}\n",
      "{'loss': 1.9166, 'grad_norm': 14.201337814331055, 'learning_rate': 1.8214285714285715e-05, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ef54594e50424b9e684b58a50b66ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7222609519958496, 'eval_accuracy': 0.5315315315315315, 'eval_f1': 0.45737646878998944, 'eval_runtime': 2.9973, 'eval_samples_per_second': 74.068, 'eval_steps_per_second': 4.671, 'epoch': 1.0}\n",
      "{'loss': 1.8175, 'grad_norm': 8.134785652160645, 'learning_rate': 1.785714285714286e-05, 'epoch': 1.07}\n",
      "{'loss': 1.8045, 'grad_norm': 9.662507057189941, 'learning_rate': 1.7500000000000002e-05, 'epoch': 1.25}\n",
      "{'loss': 1.7506, 'grad_norm': 11.8667631149292, 'learning_rate': 1.7142857142857142e-05, 'epoch': 1.43}\n",
      "{'loss': 1.5715, 'grad_norm': 13.430989265441895, 'learning_rate': 1.678571428571429e-05, 'epoch': 1.61}\n",
      "{'loss': 1.3971, 'grad_norm': 11.309673309326172, 'learning_rate': 1.642857142857143e-05, 'epoch': 1.79}\n",
      "{'loss': 1.1807, 'grad_norm': 13.833097457885742, 'learning_rate': 1.6071428571428572e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466078ba638c4737b45d22f8b62a08e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0140422582626343, 'eval_accuracy': 0.7477477477477478, 'eval_f1': 0.726659509697238, 'eval_runtime': 2.8546, 'eval_samples_per_second': 77.768, 'eval_steps_per_second': 4.904, 'epoch': 2.0}\n",
      "{'loss': 1.1072, 'grad_norm': 5.860641956329346, 'learning_rate': 1.5714285714285715e-05, 'epoch': 2.14}\n",
      "{'loss': 1.0449, 'grad_norm': 12.97945499420166, 'learning_rate': 1.535714285714286e-05, 'epoch': 2.32}\n",
      "{'loss': 0.9684, 'grad_norm': 25.847293853759766, 'learning_rate': 1.5000000000000002e-05, 'epoch': 2.5}\n",
      "{'loss': 0.8526, 'grad_norm': 18.596006393432617, 'learning_rate': 1.4642857142857144e-05, 'epoch': 2.68}\n",
      "{'loss': 0.7108, 'grad_norm': 7.087488174438477, 'learning_rate': 1.4285714285714287e-05, 'epoch': 2.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81f3568289243b1a3c522c9857d2033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5697405338287354, 'eval_accuracy': 0.7927927927927928, 'eval_f1': 0.7580934582814814, 'eval_runtime': 2.8698, 'eval_samples_per_second': 77.358, 'eval_steps_per_second': 4.878, 'epoch': 3.0}\n",
      "{'loss': 0.7705, 'grad_norm': 8.790425300598145, 'learning_rate': 1.3928571428571429e-05, 'epoch': 3.04}\n",
      "{'loss': 0.5895, 'grad_norm': 30.962587356567383, 'learning_rate': 1.3571428571428574e-05, 'epoch': 3.21}\n",
      "{'loss': 0.5916, 'grad_norm': 10.077142715454102, 'learning_rate': 1.3214285714285716e-05, 'epoch': 3.39}\n",
      "{'loss': 0.5561, 'grad_norm': 4.258518218994141, 'learning_rate': 1.2857142857142859e-05, 'epoch': 3.57}\n",
      "{'loss': 0.4217, 'grad_norm': 6.547934055328369, 'learning_rate': 1.25e-05, 'epoch': 3.75}\n",
      "{'loss': 0.4141, 'grad_norm': 9.776383399963379, 'learning_rate': 1.2142857142857142e-05, 'epoch': 3.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef538fed6c88423d9448f8d03c068ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3377887010574341, 'eval_accuracy': 0.9054054054054054, 'eval_f1': 0.9049547156935406, 'eval_runtime': 2.8669, 'eval_samples_per_second': 77.436, 'eval_steps_per_second': 4.883, 'epoch': 4.0}\n",
      "{'loss': 0.3519, 'grad_norm': 50.84397888183594, 'learning_rate': 1.1785714285714287e-05, 'epoch': 4.11}\n",
      "{'loss': 0.3405, 'grad_norm': 46.98176193237305, 'learning_rate': 1.1428571428571429e-05, 'epoch': 4.29}\n",
      "{'loss': 0.3416, 'grad_norm': 34.71142578125, 'learning_rate': 1.1071428571428572e-05, 'epoch': 4.46}\n",
      "{'loss': 0.3511, 'grad_norm': 7.940845489501953, 'learning_rate': 1.0714285714285714e-05, 'epoch': 4.64}\n",
      "{'loss': 0.3365, 'grad_norm': 3.5514538288116455, 'learning_rate': 1.0357142857142859e-05, 'epoch': 4.82}\n",
      "{'loss': 0.3165, 'grad_norm': 5.209074974060059, 'learning_rate': 1e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d13ae1fb5ef4ae087dcc636cb84f986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2447182536125183, 'eval_accuracy': 0.9279279279279279, 'eval_f1': 0.9286617580925853, 'eval_runtime': 1.3142, 'eval_samples_per_second': 168.929, 'eval_steps_per_second': 10.653, 'epoch': 5.0}\n",
      "{'loss': 0.194, 'grad_norm': 3.4705047607421875, 'learning_rate': 9.642857142857144e-06, 'epoch': 5.18}\n",
      "{'loss': 0.1609, 'grad_norm': 6.336822032928467, 'learning_rate': 9.285714285714288e-06, 'epoch': 5.36}\n",
      "{'loss': 0.2363, 'grad_norm': 9.156965255737305, 'learning_rate': 8.92857142857143e-06, 'epoch': 5.54}\n",
      "{'loss': 0.1947, 'grad_norm': 82.60816955566406, 'learning_rate': 8.571428571428571e-06, 'epoch': 5.71}\n",
      "{'loss': 0.2728, 'grad_norm': 15.034436225891113, 'learning_rate': 8.214285714285714e-06, 'epoch': 5.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a57b5894d77431aa00e05a828ebe598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25204381346702576, 'eval_accuracy': 0.9234234234234234, 'eval_f1': 0.923922939259063, 'eval_runtime': 2.8665, 'eval_samples_per_second': 77.447, 'eval_steps_per_second': 4.884, 'epoch': 6.0}\n",
      "{'loss': 0.2214, 'grad_norm': 7.526901721954346, 'learning_rate': 7.857142857142858e-06, 'epoch': 6.07}\n",
      "{'loss': 0.1412, 'grad_norm': 5.101956367492676, 'learning_rate': 7.500000000000001e-06, 'epoch': 6.25}\n",
      "{'loss': 0.1275, 'grad_norm': 1.3173834085464478, 'learning_rate': 7.1428571428571436e-06, 'epoch': 6.43}\n",
      "{'loss': 0.1055, 'grad_norm': 20.31029510498047, 'learning_rate': 6.785714285714287e-06, 'epoch': 6.61}\n",
      "{'loss': 0.2187, 'grad_norm': 35.20564651489258, 'learning_rate': 6.4285714285714295e-06, 'epoch': 6.79}\n",
      "{'loss': 0.1159, 'grad_norm': 1.2105159759521484, 'learning_rate': 6.071428571428571e-06, 'epoch': 6.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f3fc105ea2427f960dc4a1e682950b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2783849835395813, 'eval_accuracy': 0.9279279279279279, 'eval_f1': 0.928281950880821, 'eval_runtime': 2.8799, 'eval_samples_per_second': 77.087, 'eval_steps_per_second': 4.861, 'epoch': 7.0}\n",
      "{'loss': 0.0891, 'grad_norm': 9.126173973083496, 'learning_rate': 5.7142857142857145e-06, 'epoch': 7.14}\n",
      "{'loss': 0.1089, 'grad_norm': 4.319641590118408, 'learning_rate': 5.357142857142857e-06, 'epoch': 7.32}\n",
      "{'loss': 0.1396, 'grad_norm': 12.745698928833008, 'learning_rate': 5e-06, 'epoch': 7.5}\n",
      "{'loss': 0.1208, 'grad_norm': 27.966938018798828, 'learning_rate': 4.642857142857144e-06, 'epoch': 7.68}\n",
      "{'loss': 0.1074, 'grad_norm': 13.827014923095703, 'learning_rate': 4.2857142857142855e-06, 'epoch': 7.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d20231325f40059050f03b3410537e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2477552741765976, 'eval_accuracy': 0.9324324324324325, 'eval_f1': 0.9326275165910913, 'eval_runtime': 2.8637, 'eval_samples_per_second': 77.522, 'eval_steps_per_second': 4.889, 'epoch': 8.0}\n",
      "{'loss': 0.0617, 'grad_norm': 1.3675810098648071, 'learning_rate': 3.928571428571429e-06, 'epoch': 8.04}\n",
      "{'loss': 0.0725, 'grad_norm': 1.8335506916046143, 'learning_rate': 3.5714285714285718e-06, 'epoch': 8.21}\n",
      "{'loss': 0.1063, 'grad_norm': 1.872449278831482, 'learning_rate': 3.2142857142857147e-06, 'epoch': 8.39}\n",
      "{'loss': 0.0842, 'grad_norm': 0.826352596282959, 'learning_rate': 2.8571428571428573e-06, 'epoch': 8.57}\n",
      "{'loss': 0.0445, 'grad_norm': 11.768636703491211, 'learning_rate': 2.5e-06, 'epoch': 8.75}\n",
      "{'loss': 0.0507, 'grad_norm': 7.975843906402588, 'learning_rate': 2.1428571428571427e-06, 'epoch': 8.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc08d6a032b413c8320dcfb0af22f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26919621229171753, 'eval_accuracy': 0.9279279279279279, 'eval_f1': 0.9284708794155863, 'eval_runtime': 2.8794, 'eval_samples_per_second': 77.101, 'eval_steps_per_second': 4.862, 'epoch': 9.0}\n",
      "{'loss': 0.0568, 'grad_norm': 1.933126449584961, 'learning_rate': 1.7857142857142859e-06, 'epoch': 9.11}\n",
      "{'loss': 0.0573, 'grad_norm': 1.282114863395691, 'learning_rate': 1.4285714285714286e-06, 'epoch': 9.29}\n",
      "{'loss': 0.0704, 'grad_norm': 2.0959694385528564, 'learning_rate': 1.0714285714285714e-06, 'epoch': 9.46}\n",
      "{'loss': 0.0398, 'grad_norm': 0.7674557566642761, 'learning_rate': 7.142857142857143e-07, 'epoch': 9.64}\n",
      "{'loss': 0.1048, 'grad_norm': 9.13603687286377, 'learning_rate': 3.5714285714285716e-07, 'epoch': 9.82}\n",
      "{'loss': 0.0683, 'grad_norm': 1.1718531847000122, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa64398533143cb8441875509a5ecf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2801665961742401, 'eval_accuracy': 0.9279279279279279, 'eval_f1': 0.92844058922524, 'eval_runtime': 1.5171, 'eval_samples_per_second': 146.334, 'eval_steps_per_second': 9.228, 'epoch': 10.0}\n",
      "{'train_runtime': 1765.3519, 'train_samples_per_second': 5.019, 'train_steps_per_second': 0.317, 'train_loss': 0.5914577308510031, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=560, training_loss=0.5914577308510031, metrics={'train_runtime': 1765.3519, 'train_samples_per_second': 5.019, 'train_steps_per_second': 0.317, 'total_flos': 582822383493120.0, 'train_loss': 0.5914577308510031, 'epoch': 10.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66db8c554bc843d29b8f3fda6514dd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.2477552741765976, 'eval_accuracy': 0.9324324324324325, 'eval_f1': 0.9326275165910913, 'eval_runtime': 1.4965, 'eval_samples_per_second': 148.348, 'eval_steps_per_second': 9.355, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ebee81beb14be1b4758a051e69087b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.88      0.85      0.87        27\n",
      "    Calmness       0.97      1.00      0.98        30\n",
      "  Excitement       0.96      0.93      0.95        28\n",
      " Frustration       0.81      0.88      0.85        25\n",
      "   Gratitude       0.96      0.96      0.96        26\n",
      "Indifference       0.93      0.93      0.93        28\n",
      "         Joy       0.96      0.96      0.96        28\n",
      "     Sadness       0.97      0.93      0.95        30\n",
      "\n",
      "    accuracy                           0.93       222\n",
      "   macro avg       0.93      0.93      0.93       222\n",
      "weighted avg       0.93      0.93      0.93       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "test_logits = trainer.predict(test_dataset).predictions\n",
    "y_pred = torch.argmax(torch.tensor(test_logits), axis=1).numpy()\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment_model\\\\tokenizer_config.json',\n",
       " './sentiment_model\\\\special_tokens_map.json',\n",
       " './sentiment_model\\\\sentencepiece.bpe.model',\n",
       " './sentiment_model\\\\added_tokens.json',\n",
       " './sentiment_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(label_encoder, \"./label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = joblib.load(\"./label_encoder.pkl\")\n",
    "\n",
    "saved_model_path = \"./sentiment_model\"\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(saved_model_path)\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: à®Žà®©à®•à¯à®•à¯ à®‡à®©à¯à®±à¯ à®®à®¿à®•à®µà¯à®®à¯ à®®à®•à®¿à®´à¯à®šà¯à®šà®¿. => Predicted Sentiment: Joy\n",
      "Text: à®¨à®¾à®©à¯ à®®à®¿à®•à®µà¯à®®à¯ à®•à¯‹à®ªà®®à®¾à®• à®‰à®³à¯à®³à¯‡à®©à¯. => Predicted Sentiment: Anger\n",
      "Text: à®¨à®¾à®©à¯ à®‡à®©à¯à®±à¯ à®šà¯‹à®°à¯à®µà®¾à®• à®‡à®±à¯à®•à¯à®•à®¿à®±à¯‡à®©à¯. => Predicted Sentiment: Sadness\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(texts):\n",
    "    encodings = loaded_tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    outputs = loaded_model(**encodings)\n",
    "    predictions = torch.argmax(outputs.logits, axis=1).numpy()\n",
    "    sentiment_labels = label_encoder.inverse_transform(predictions)\n",
    "    return sentiment_labels\n",
    "new_texts = [\n",
    "    \"à®Žà®©à®•à¯à®•à¯ à®‡à®©à¯à®±à¯ à®®à®¿à®•à®µà¯à®®à¯ à®®à®•à®¿à®´à¯à®šà¯à®šà®¿.\",\n",
    "    \"à®¨à®¾à®©à¯ à®®à®¿à®•à®µà¯à®®à¯ à®•à¯‹à®ªà®®à®¾à®• à®‰à®³à¯à®³à¯‡à®©à¯.\",\n",
    "    \"à®¨à®¾à®©à¯ à®‡à®©à¯à®±à¯ à®šà¯‹à®°à¯à®µà®¾à®• à®‡à®±à¯à®•à¯à®•à®¿à®±à¯‡à®©à¯.\"\n",
    "]\n",
    "predictions = predict_sentiment(new_texts)\n",
    "for text, sentiment in zip(new_texts, predictions):\n",
    "    print(f\"Text: {text} => Predicted Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b670e81aa9e434d8093c549bae86211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub\\models--Rajkumar57--tamilsentiment-model. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729b47a9138c4e5ea3c268749c905ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9e7f44a6cb4d3aa763075294b72355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d34218596e4bef9529ac9b8eb23a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27aa73e137d04e7abbbd374ccc7db9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb64fbf0dd4451eb9850d52f5b3ae2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment label: Indifference\n"
     ]
    }
   ],
   "source": [
    "#Hugging face\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import joblib  \n",
    "import os\n",
    "\n",
    "\n",
    "label_encoder_path = \"C:/Users/lenovo/Desktop/model/Tamil/Tamilsent/label_encoder.pkl\"\n",
    "\n",
    "\n",
    "label_encoder = joblib.load(label_encoder_path) \n",
    "\n",
    "model_name = \"Rajkumar57/tamilsentiment-model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "text = \"à®‡à®¨à¯à®¤ à®’à®°à¯ à®‰à®¤à®¾à®°à®£à®®à¯.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predicted_class_idx = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "\n",
    "print(f\"Predicted sentiment label: {predicted_class_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
